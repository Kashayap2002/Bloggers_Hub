{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kashayap2002/Bloggers_Hub/blob/master/imdb_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f942adde",
      "metadata": {
        "id": "f942adde"
      },
      "source": [
        "# import relevant libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "227e2345",
      "metadata": {
        "id": "227e2345"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "import scipy.stats as stats\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "RSngi4aovkDv",
        "outputId": "02956104-1aa6-48e0-ddf5-de6b107a6161"
      },
      "id": "RSngi4aovkDv",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    127\u001b[0m   )\n\u001b[1;32m    128\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f1c7d06",
      "metadata": {
        "id": "6f1c7d06"
      },
      "source": [
        "load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06f4cc10",
      "metadata": {
        "id": "06f4cc10",
        "outputId": "587dcd44-7645-4652-f350-89da00f51efa"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>I thought this movie did a down right good job...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>I am a Catholic taught in parochial elementary...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>I'm going to have to disagree with the previou...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>No one expects the Star Trek movies to be high...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  review sentiment\n",
              "0      One of the other reviewers has mentioned that ...  positive\n",
              "1      A wonderful little production. <br /><br />The...  positive\n",
              "2      I thought this was a wonderful way to spend ti...  positive\n",
              "3      Basically there's a family where a little boy ...  negative\n",
              "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
              "...                                                  ...       ...\n",
              "49995  I thought this movie did a down right good job...  positive\n",
              "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
              "49997  I am a Catholic taught in parochial elementary...  negative\n",
              "49998  I'm going to have to disagree with the previou...  negative\n",
              "49999  No one expects the Star Trek movies to be high...  negative\n",
              "\n",
              "[50000 rows x 2 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data=pd.read_csv('IMDB Dataset.csv')\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe8cb36d",
      "metadata": {
        "id": "fe8cb36d"
      },
      "source": [
        "# Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c195a1a",
      "metadata": {
        "id": "4c195a1a",
        "outputId": "a88f9482-7f1c-4f54-e476-290a98b4e8a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 50000 entries, 0 to 49999\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   review     50000 non-null  object\n",
            " 1   sentiment  50000 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 781.4+ KB\n"
          ]
        }
      ],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ce6fa48",
      "metadata": {
        "id": "9ce6fa48"
      },
      "source": [
        "there is no null values above dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "311f37ac",
      "metadata": {
        "id": "311f37ac",
        "outputId": "786bf698-953f-4689-8998-a48beaa961dc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>50000</td>\n",
              "      <td>50000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>49582</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>Loved today's show!!! It was a variety and not...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>5</td>\n",
              "      <td>25000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   review sentiment\n",
              "count                                               50000     50000\n",
              "unique                                              49582         2\n",
              "top     Loved today's show!!! It was a variety and not...  positive\n",
              "freq                                                    5     25000"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6ebbc81",
      "metadata": {
        "id": "f6ebbc81",
        "outputId": "2ec14472-f2ee-4103-8952-bf99e3bdb455"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "positive    25000\n",
              "negative    25000\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data['sentiment'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e23a692",
      "metadata": {
        "id": "2e23a692"
      },
      "source": [
        "here dataset is equally divided for positive and negative sentiments. so our model should work well while training and testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d658c72",
      "metadata": {
        "id": "9d658c72",
        "outputId": "5699409a-8004-4e8b-cc1c-a0a0d3915c01"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['review', 'sentiment'], dtype='object')"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "072bb050",
      "metadata": {
        "id": "072bb050",
        "outputId": "88685021-f60e-4957-e883-75c8c070e921"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(50000, 2)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97e30aec",
      "metadata": {
        "id": "97e30aec"
      },
      "source": [
        "split the train dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0278b12",
      "metadata": {
        "id": "d0278b12",
        "outputId": "924651d9-eea0-4800-ceea-49abc0a28fe5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(40000,) (10000,)\n",
            "(40000,) (10000,)\n"
          ]
        }
      ],
      "source": [
        "#let 40000 data for training and 10000 data for testing.\n",
        "train_review=data.review[:40000]\n",
        "train_sentiment=data.sentiment[:40000]\n",
        "test_review=data.review[40000:]\n",
        "test_sentiment=data.sentiment[40000:]\n",
        "print(train_review.shape,test_review.shape)\n",
        "print(train_sentiment.shape,test_sentiment.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4fece819",
      "metadata": {
        "id": "4fece819"
      },
      "source": [
        "Text Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "335d37de",
      "metadata": {
        "id": "335d37de",
        "outputId": "c1954320-14b5-42c9-d032-4d498962d10b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting textblob\n",
            "  Using cached textblob-0.18.0.post0-py3-none-any.whl (626 kB)\n",
            "Collecting nltk>=3.8\n",
            "  Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
            "Requirement already satisfied: joblib in c:\\users\\kiit\\new folder\\lib\\site-packages (from nltk>=3.8->textblob) (1.1.1)\n",
            "Requirement already satisfied: tqdm in c:\\users\\kiit\\new folder\\lib\\site-packages (from nltk>=3.8->textblob) (4.64.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\kiit\\new folder\\lib\\site-packages (from nltk>=3.8->textblob) (2022.7.9)\n",
            "Requirement already satisfied: click in c:\\users\\kiit\\new folder\\lib\\site-packages (from nltk>=3.8->textblob) (8.0.4)\n",
            "Requirement already satisfied: colorama in c:\\users\\kiit\\new folder\\lib\\site-packages (from click->nltk>=3.8->textblob) (0.4.6)\n",
            "Installing collected packages: nltk, textblob\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.7\n",
            "    Uninstalling nltk-3.7:\n",
            "      Successfully uninstalled nltk-3.7\n",
            "Successfully installed nltk-3.8.1 textblob-0.18.0.post0\n"
          ]
        }
      ],
      "source": [
        "!pip install textblob\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3f2d8c2",
      "metadata": {
        "id": "a3f2d8c2"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from wordcloud import WordCloud,STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "from bs4 import BeautifulSoup\n",
        "from textblob import TextBlob\n",
        "from textblob import Word\n",
        "from nltk.tokenize.toktok import ToktokTokenizer\n",
        "from nltk.stem import LancasterStemmer,WordNetLemmatizer\n",
        "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c6ea4c8",
      "metadata": {
        "id": "7c6ea4c8"
      },
      "outputs": [],
      "source": [
        "tokenizer=ToktokTokenizer()\n",
        "#set english stopwords\n",
        "stopword_list=nltk.corpus.stopwords.words('english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c62d6d8e",
      "metadata": {
        "id": "c62d6d8e"
      },
      "outputs": [],
      "source": [
        "#remove html strips\n",
        "def strip_html(text):\n",
        "    soup = BeautifulSoup(text, \"html.parser\")\n",
        "    return soup.get_text()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2fa80781",
      "metadata": {
        "id": "2fa80781"
      },
      "outputs": [],
      "source": [
        "#remove square bracket\n",
        "import re,string,unicodedata\n",
        "def remove_between_square_brackets(text):\n",
        "    return re.sub('\\[[^]]*\\]', '', text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22680c8a",
      "metadata": {
        "id": "22680c8a"
      },
      "outputs": [],
      "source": [
        "#Removing the noisy text\n",
        "def denoise_text(text):\n",
        "    text = strip_html(text)\n",
        "    text = remove_between_square_brackets(text)\n",
        "    return text\n",
        "#Apply function on review column\n",
        "data['review']=data['review'].apply(denoise_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d2bc62e",
      "metadata": {
        "id": "0d2bc62e"
      },
      "outputs": [],
      "source": [
        "#Define function for removing special characters\n",
        "def remove_special_character(text, remove_digits=True):\n",
        "    pattern=r'[^a-zA-z0-9\\s]'\n",
        "    text=re.sub(pattern,'',text)\n",
        "    return text\n",
        "#Apply function on review column\n",
        "data['review']=data['review'].apply(remove_special_character)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e1a2268",
      "metadata": {
        "id": "0e1a2268",
        "outputId": "a5ac51be-5125-4957-ad91-f274e6d91a70"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production The filming tech...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically theres a family where a little boy J...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Matteis Love in the Time of Money is a ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  sentiment\n",
              "0  One of the other reviewers has mentioned that ...          1\n",
              "1  A wonderful little production The filming tech...          1\n",
              "2  I thought this was a wonderful way to spend ti...          1\n",
              "3  Basically theres a family where a little boy J...          0\n",
              "4  Petter Matteis Love in the Time of Money is a ...          1"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def Convert_to_bin(text, remove_digits=True):\n",
        "  if text=='positive':\n",
        "    text= 1\n",
        "  else:\n",
        "    text=0\n",
        "  return text\n",
        "data['sentiment']=data['sentiment'].apply(Convert_to_bin)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e172d80",
      "metadata": {
        "id": "4e172d80"
      },
      "source": [
        "Stemming is a technique for eliminating affixes from words in order to retrieve the base form. It’s the same as pruning a tree’s branches down to the trunk. The stem of the terms eating, eats, and eaten, for example, is eat."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbb735db",
      "metadata": {
        "id": "fbb735db"
      },
      "outputs": [],
      "source": [
        "#Stemming the text\n",
        "def simple_stemmer(text):\n",
        "    ps=nltk.porter.PorterStemmer()\n",
        "    text= ' '.join([ps.stem(word) for word in text.split()])\n",
        "    return text\n",
        "#Apply function on review column\n",
        "data['review']=data['review'].apply(simple_stemmer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a61e1340",
      "metadata": {
        "id": "a61e1340"
      },
      "source": [
        "Stop words are words that have little or no meaning, especially when synthesising meaningful aspects from the text.<br>\n",
        "Stop words are words that are filtered out of natural language data (text) before or after it is processed in computers. While “stop words” usually refers to a language’s most common terms, all-natural language processing algorithms don’t employ a single universal list.<br>\n",
        "Stopwords include words such as a, an, the, and others."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e31b4579",
      "metadata": {
        "id": "e31b4579"
      },
      "outputs": [],
      "source": [
        "#set stopwords to english\n",
        "stop=set(stopwords.words('english'))\n",
        "print(stop)\n",
        "\n",
        "#removing the stopwords\n",
        "def remove_stopwords(text, is_lower_case=False):\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    tokens = [token.strip() for token in tokens]\n",
        "    if is_lower_case:\n",
        "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
        "    else:\n",
        "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
        "    filtered_text = ' '.join(filtered_tokens)\n",
        "    return filtered_text\n",
        "#Apply function on review column\n",
        "data['review']=data['review'].apply(remove_stopwords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "036885c0",
      "metadata": {
        "id": "036885c0"
      },
      "outputs": [],
      "source": [
        "#normalized train reviews\n",
        "norm_train_reviews=data.review[:40000]\n",
        "norm_train_reviews[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7454e101",
      "metadata": {
        "id": "7454e101"
      },
      "outputs": [],
      "source": [
        "#Normalized test reviews\n",
        "norm_test_reviews=data.review[40000:]\n",
        "norm_test_reviews[45005]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa113315",
      "metadata": {
        "id": "aa113315"
      },
      "outputs": [],
      "source": [
        "##convert dataframe to string\n",
        "norm_test_string=norm_test_reviews.to_string()\n",
        "#spelling correction using Textblob\n",
        "norm_test_spelling=TextBlob(norm_test_string)\n",
        "print(norm_test_spelling.correct())\n",
        "#Tokenization using Textblob\n",
        "norm_test_words=norm_test_spelling.words\n",
        "norm_test_words"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f4a89de",
      "metadata": {
        "id": "6f4a89de"
      },
      "source": [
        "Text normalisation is the process of converting previously uncanonical text into a single canonical form. Because input is guaranteed to be consistent before operations are done on it, normalising text before storing or processing it allows for separation of concerns."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b70ecc03",
      "metadata": {
        "id": "b70ecc03"
      },
      "source": [
        "Bags of Word Model<br>It is used to convert text documents to numerical vectors or bag of words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e841167d",
      "metadata": {
        "id": "e841167d"
      },
      "outputs": [],
      "source": [
        "#Count vectorizer for bag of words\n",
        "cv=CountVectorizer(min_df=0,max_df=1,binary=False,ngram_range=(1,3))\n",
        "#transformed train reviews\n",
        "cv_train_reviews=cv.fit_transform(norm_train_reviews)\n",
        "#transformed test reviews\n",
        "cv_test_reviews=cv.transform(norm_test_reviews)\n",
        "\n",
        "print('BOW_cv_train:',cv_train_reviews.shape)\n",
        "print('BOW_cv_test:',cv_test_reviews.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "990a62ad",
      "metadata": {
        "id": "990a62ad"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b23b36af",
      "metadata": {
        "id": "b23b36af"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}